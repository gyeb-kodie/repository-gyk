{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4d684172-4b94-42cf-bda2-e11952420d86",
   "metadata": {},
   "source": [
    "# Homework 10\n",
    "#### Course Notes\n",
    "**Language Models:** https://github.com/rjenki/BIOS512/tree/main/lecture17  \n",
    "**Unix:** https://github.com/rjenki/BIOS512/tree/main/lecture18  \n",
    "**Docker:** https://github.com/rjenki/BIOS512/tree/main/lecture19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d839a5ba-62f4-4699-baea-018afda70786",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "#### Make a language model that uses ngrams and allows the user to specify start words, but uses a random start if one is not specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef37d3a-a6ad-42ae-9e16-7d7338c9ce49",
   "metadata": {},
   "source": [
    "#### a) Make a function to tokenize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c218dbd0-e9fe-4ad2-9f30-35c9b53309ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "also installing the dependency ‘SnowballC’\n",
      "\n",
      "\n",
      "Installing package into ‘/srv/rlibs’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"httr\")\n",
    "install.packages(\"tokenizers\")\n",
    "install.packages(\"stringr\")\n",
    "\n",
    "library(httr)\n",
    "library(tokenizers)\n",
    "library(stringr)\n",
    "\n",
    "tokenize_text <- function(text) {\n",
    "  tokenizers::tokenize_words(text, lowercase=TRUE, strip_punct=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86145513-294b-4894-a02c-8ae60e2c616e",
   "metadata": {},
   "source": [
    "#### b) Make a function generate keys for ngrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f45ff2-0724-4754-96ac-34b41fe483be",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_from <- function(ngram, sep = \"\\x1f\") {\n",
    "  paste(ngram, collapse=sep)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52988c2c-b230-467f-b519-72bc85b93b43",
   "metadata": {},
   "source": [
    "#### c) Make a function to build an ngram table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7449de94-f5fd-4bd7-aa54-277cee857061",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_ngram_table <- function(tokens, n, sep = \"\\x1f\") {\n",
    "  if (length(tokens) < n) return(new.env(parent = emptyenv()))\n",
    "  tbl <- new.env(parent = emptyenv())\n",
    "  for (i in seq_len(length(tokens) - n + 1L)) {\n",
    "    ngram <- tokens[i:(i + n - 2L)]\n",
    "    next_word <- tokens[i + n - 1L]\n",
    "    key <- paste(ngram, collapse = sep)\n",
    "    counts <- if (!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "    if (next_word %in% names(counts)) {\n",
    "      counts[[next_word]] <- counts[[next_word]] + 1L\n",
    "    } else {\n",
    "      counts[[next_word]] <- 1L\n",
    "    }\n",
    "    tbl[[key]] <- counts\n",
    "  }\n",
    "  tbl\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca6db37-abce-4705-9784-e1b898174f00",
   "metadata": {},
   "source": [
    "#### d) Function to digest the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0b3010d-c02b-46ba-a62a-bfc5e39026f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_text <- function(text, n) {\n",
    "  tokens <- tokenize_text(text)\n",
    "  build_ngram_table(tokens, n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fff313-0f13-479b-94df-7588c19fdd3d",
   "metadata": {},
   "source": [
    "#### e) Function to digest the url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1391cac-b646-4c27-8362-f95a03627740",
   "metadata": {},
   "outputs": [],
   "source": [
    "digest_url <- function(url, n) {\n",
    "  res <- httr::GET(url)\n",
    "  txt <- httr::content(res, as = \"text\", encoding = \"UTF-8\")\n",
    "  digest_text(txt,n)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa4e73-ee6f-4569-9a54-9d7f7eb3f80a",
   "metadata": {},
   "source": [
    "#### f) Function that gives random start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56facd26-1de7-4372-a7ea-3e736ebaecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_start <- function(tbl, sep = \"\\x1f\") {\n",
    "  keys <- ls(envir = tbl, all.names=TRUE)\n",
    "  if (length(keys)==0) stop(\"No n-grams available. Digest text first.\")\n",
    "  picked <- sample(keys, 1)\n",
    "  strsplit(picked, sep, fixed=TRUE)[[1]]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e998fb24-f2d6-41bc-a751-1f6accd3411f",
   "metadata": {},
   "source": [
    "#### g) Function to predict the next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "854661f8-5c2d-465d-9e8b-11314fb85d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_next_word <- function(tbl, ngram, sep = \"\\x1f\") {\n",
    "  key <- paste(ngram, collapse = sep)\n",
    "  counts <- if(!is.null(tbl[[key]])) tbl[[key]] else integer(0)\n",
    "  if (length(counts) == 0) return(NA_character_)\n",
    "  sample(names(counts), size=1, prob=as.numeric(counts))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347f4002-4932-42c4-a4af-8689293a5857",
   "metadata": {},
   "source": [
    "#### h) Function that puts everything together. Specify that if the user does not give a start word, then the random start will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6044823-c02a-4a5b-a016-24ae7253d4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_ngram_generator <- function(tbl, n, sep = \"\\x1f\") {\n",
    "  force(tbl); n <- as.integer(n); force(sep)\n",
    "  function(start_words = NULL, length = 10L) {\n",
    "    if ((is.null(start_words)) || length(start_words) != n - 1L) {\n",
    "      start_words <- random_start(tbl, sep=sep)\n",
    "    }\n",
    "    word_sequence <- start_words\n",
    "    for (i in seq_len(max(0L, length - length(start_words)))) {\n",
    "      ngram <- tail(word_sequence, n - 1L)\n",
    "      next_word <- predict_next_word(tbl, ngram, sep=sep)\n",
    "      if (is.na(next_word)) break\n",
    "      word_sequence <- c(word_sequence, next_word)\n",
    "    }\n",
    "    paste(word_sequence, collapse= \" \")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b742c67-907c-4bc7-8df1-c84fa65a7554",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "#### For this question, set `seed=2025`.\n",
    "#### a) Test your model using a text file of [Grimm's Fairy Tails](https://www.gutenberg.org/cache/epub/2591/pg2591.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f05cbec8-451e-4809-9ab4-84130b7f861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/2591/pg2591.txt\"\n",
    "tbl3 <- digest_url(url, n=3)\n",
    "gen3 <- make_ngram_generator(tbl3, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1dc7089-45af-49fe-8550-3f15eff4e4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i) Start words = 'the king'\n",
      " the king has forbidden me to marry another husband am not i shall ride upon \n"
     ]
    }
   ],
   "source": [
    "#i)\n",
    "set.seed(2025)  \n",
    "output_i <- gen3(start_words = c(\"the\", \"king\"), length = 15)\n",
    "cat(\"i) Start words = 'the king'\\n\", output_i, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d21a88-935b-4247-97ff-0db5767d498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"the king has forbidden me to marry another husband am not i shall ride upon\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e5f6c0-7fe7-4c52-ae7b-94f549326a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ii) Random start\n",
      " a rapid stream how shall i kill her on a sudden looked behind the other \n"
     ]
    }
   ],
   "source": [
    "#ii)\n",
    "set.seed(123)  \n",
    "output_ii <- gen3(length = 15)\n",
    "cat(\"\\nii) Random start\\n\", output_ii, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e6859-28dc-4db4-8743-35667527e9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"a rapid stream how shall i kill her on a sudden looked behind the other\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e04b167-7f2c-4e0f-88e7-86ba5e8d74cc",
   "metadata": {},
   "source": [
    "#### b) Test your model using a text file of [Ancient Armour and Weapons in Europe](https://www.gutenberg.org/cache/epub/46342/pg46342.txt)\n",
    "#### i) Using n=3, with the start word(s) \"the king\", with length=15. \n",
    "#### ii) Using n=3, with no start word, with length=15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cedc3f0f-a6cc-4e87-9a91-1707f11764a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#b)\n",
    "url <- \"https://www.gutenberg.org/cache/epub/46342/pg46342.txt\"\n",
    "tbl3 <- digest_url(url, n=3)\n",
    "gen3 <- make_ngram_generator(tbl3, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c27b640-8a7a-4e75-8302-506a0ee7896d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i) Start words = 'the king'\n",
      " the king he added to the entire exclusion of the swords were made prisoners the \n"
     ]
    }
   ],
   "source": [
    "#i)\n",
    "set.seed(2025)  \n",
    "output_i <- gen3(start_words = c(\"the\", \"king\"), length = 15)\n",
    "cat(\"i) Start words = 'the king'\\n\", output_i, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1fc37f-79a2-47e6-9aa4-cb316c525635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"the king he added to the entire exclusion of the swords were made prisoners the\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dbcd494-4273-466d-8096-d82a8266c7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ii) Random start\n",
      " lamentation de lemburn came forth completely armed after the fashion of this may be seen \n"
     ]
    }
   ],
   "source": [
    "#ii)\n",
    "set.seed(2025) \n",
    "output_ii <- gen3(length = 15)\n",
    "cat(\"\\nii) Random start\\n\", output_ii, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "164acee6-92db-43a6-a1d2-89fe677b8c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"lamentation de lemburn came forth completely armed after the fashion of this may be seen\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fb37ad-8e7c-4e62-afc0-ba46d46401fc",
   "metadata": {},
   "source": [
    "#### c) Explain in 1-2 sentences the difference in content generated from each source.\n",
    "\n",
    "The sentence in 2b draws on words more used in fairy tales (marry, husband, stream), while the sentence in 2c draws on more military or monarchy-related terms (exclusion, swords, prisoners, armed). This difference in content generated is due to the different bodies of text from which we sourced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e45972-f441-4d07-9073-fcddd6146cbd",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "#### a) What is a language learning model? \n",
    "\n",
    "A language learning model is a tool that identifies the probability of the distribution of words and uses that probability to predict the next word in a sentence based on what came before.\n",
    "\n",
    "\n",
    "#### b) Imagine the internet goes down and you can't run to your favorite language model for help. How do you run one locally?\n",
    "\n",
    "OLLAMA, a wrapper around Docker, is what can run a language model locally in the event that the internet is down. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85a743b-f814-4a53-96e6-8bccb3d34ab8",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "#### Explain what the following vocab words mean in the context of typing `mkdir project` into the command line. If the term doesn't apply to this command, give the definition and/or an example.\n",
    "| Term | Meaning |  \n",
    "|------|---------|\n",
    "| **Shell** | A shell exists around an operating system but lets you interact with it. |\n",
    "| **Terminal emulator** | A terminal emulator hosts a shell, providing the interface. |\n",
    "| **Process** | What is running. It communicates using standard input/standard output. |\n",
    "| **Signal** | What is sent to a process telling it to do something. |\n",
    "| **Standard input** | A characteristic of a process; it reads characters in. |\n",
    "| **Standard output** | A characteristic of a process; what the process reads in is fed to the standard output. |\n",
    "| **Command line argument** | These arguments are passed to processes. |\n",
    "| **The environment** | What a process can \"see\" while running. |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1332ff27-ca3f-4f7e-b4b9-07ead0358dd2",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "#### Consider the following command `find . -iname \"*.R\" | xargs grep read_csv`.\n",
    "#### a) What are the programs?\n",
    "\n",
    "The programs are find, xargs, and grep\n",
    "\n",
    "#### b) Explain what this command is doing, part by part.\n",
    "\n",
    "This line is: searching the current directory; finding files ending in \".R\"; thensearching within identified files for the use of \"read_csv.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69771ac7-865e-4d82-aa25-a39e7c1ab095",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "#### Install Docker on your machine. See [here](https://github.com/rjenki/BIOS512/blob/main/lecture18/docker_install.md) for instructions. \n",
    "#### a) Show the response when you run `docker run hello-world`.\n",
    "\n",
    "I would see \"Hello from Docker!\"\n",
    "\n",
    "#### b) Access Rstudio through a Docker container. Set your password and make sure your files show up on the Rstudio server. Type the command and the output you get below.\n",
    "\n",
    "The input would be docker run -it -e PASSWORD=<(mypassword)> -p 8787:8787 rocker/verse; the output would be the password I set.\n",
    "\n",
    "#### c) How do you log in to the RStudio server?\n",
    "\n",
    "I would go to  http://localhost:8787 and enter the username rstudio and the password I set up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
